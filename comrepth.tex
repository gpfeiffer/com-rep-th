%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  comrepth.tex
%%
\documentclass[12pt]{amsart}

\title{Computational Representation Theory}

\usepackage[euler-digits]{eulervm}
\usepackage[a4paper,margin=1in,includeheadfoot]{geometry}
\usepackage{amssymb}
\usepackage[all]{xy}
\usepackage{enumerate}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}

\renewcommand{\emptyset}{\varnothing}

\DeclareMathOperator{\Aut}{\mathsf{Aut}}
\DeclareMathOperator{\Fix}{\mathsf{Fix}}
\DeclareMathOperator{\End}{\mathsf{End}}
\DeclareMathOperator{\Sym}{\mathsf{Sym}}
\DeclareMathOperator{\GL}{\mathsf{GL}}

\newcommand{\Size}[1]{\left| #1 \right|}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:intro}

Representation theory of finite groups is concerned with the ways of writing a group $G$ as a group of automorphisms and being able to analyze the group in terms of these automorphisms.\\
If $X$ is a structure then we have $\End(X)=\{f:X\rightarrow X$, $f$ compatible with structure$\}$.  The set of automorphisms is given by $\Aut(X)=\{f\in \End(X)$, $f$ invertible$\}$.  $\Aut(X)$ is a groups under composition, as it satisfies the group axioms:
\begin{itemize}
\item compositions of automorphisms are automorphisms; \item composition of maps is associative; \item id$_X$ is the identity; \item $f\in \Aut(X)$ is invertible by definition.
\end{itemize}
A representation realises a group $G$ as a group of automorphisms of some structure $X$.  It associates to each element $a\in G$ an automorphism of $X$ in a way that is compatible with the multiplication in $G$.

\begin{definition}
A \emph{representation} of a group $G$ is a homomorphism $\phi:G\rightarrow \Aut(X)$ for some structure $X$.  For any representation we have
\begin{itemize}
\item $\phi(a^{-1})=\phi(a)^{-1}$; \item $\phi(1)=id_X$; \item $\phi(ab)=\phi(a)\phi(b)$.
\end{itemize}
\end{definition}

\begin{example}
Let $X=\{1,\ldots,n\}$ where $n\in\mathbb{N}$, ie. $X$ is a finite set.  Then $\End(X)=\{f:x\rightarrow X\}=X^X=X^n$ and $\Size{\End(X)}=n^n$.  We have $\Aut(X)=\Sym(X)=\Sym_n$, the symmetric group whose elements are all the permutations of $X$, with $\Size{\Aut(X)}=n!$.  The permutation representation is $\phi:G\rightarrow \Sym(X)$.
\end{example}

\begin{example}
Let $X=\mathbb{F}^n$, a vector space over a field $\mathbb{F}$.  Then $\End(X)=\mathbb{F}^{n\times n}$ and if $\Size{\mathbb{F}}=q$ then $\Size{\End(X)}=q^{n^2}$.  We have $\Aut(X)=\GL(X)=\GL_n(\mathbb{F})$, the general linear group of all invertible matrices over $\mathbb{F}$.  In this case,
\begin{align*}
\Size{\GL_n(\mathbb{F})} &= (q^n-1)(q^n-q)(q^n-q^2)\ldots(q^n-q^{n-1})\\
&= q^{n\choose 2}\prod_{i=1}^n(q^i-1).
\end{align*}
The matrix representation is $\phi:G\rightarrow \GL_n(\mathbb{F})$.
\end{example}

Finding \textbf{one} representation of a group gives a concrete description of the group, allowing us to perform explicit calculations with its elements.  Classifying \textbf{all} representations provides structural information about the group and yields general results which are otherwise very difficult to prove.

\begin{example}
Let $X = G$. $\Aut(G) =$ all invertible group homomorphisms $f: G \rightarrow G$.
\end{example}

\begin{example}
$G = \mathbb{Z}_{n} = \mathbb{Z} / n \mathbb{Z} = \left\{ 0, \ldots , n - 1 \right\}$
$+_{n}$ and $\cdot_{n}$ are taken modulo n:
$a +_{n} b := ( a + b ) mod n$ for $a, b \in \mathbb{Z}_{n}$
$\left( \mathbb{Z}_{n}, +_{n} \right)$ is a commutative group. We want to find
$\End(X)$
Thus we need to find all homomorphisms $f: \mathbb{Z}_{n} \rightarrow \mathbb{Z}_{n}$.


$$f(0) = 0$$
$$a \in \mathbb{Z}_{n} : a = \underbrace{1 + \ldots + 1}_{a \text{ times}}$$
$$f(a) = f( \underbrace{1 + \ldots + 1}_{a \text{ times}})$$
$$ = \underbrace{f(1) + \ldots + f(1)}_{a \text{ times}}$$

$f$ is determined by choosing $f(1)$, any choice in $\mathbb{Z}_{n}$ is possible. Then $f$ is multiplication by $f(1)$.

$$\End(X) = \left\{ X \mapsto X \cdot c : c \in \mathbb{Z}_{n} \right\}$$
$$\Aut(X) = \mathbb{Z}_{n}^{\ast} = \left\{ c \in \mathbb{Z}_{n} : gcd ( c, n ) = 1 \right\}$$
\end{example}

\begin{example}
The automorphisms of a permutation.
$X = \left\{ 1, \ldots, n \right\}, R \subseteq X^{2}$ is a binary relation (structure on $X$).
$$\End(X, R) = \left\{ f: X \rightarrow X, x R y \Rightarrow f(x) R f(y) \right\}$$
$$\Aut(X) = \left\{ \text{permutations in } \End(X) \right\}$$

A permutation of $X$ is a binary relation:
\begin{itemize}
\item As a function $x \mapsto x^{\alpha}$:
$$\rightarrow \Aut( \alpha ) = \left\{\text{ individual cycles, swap cycles of the same length} \right\}.$$
\noindent Different ways of writing $\alpha$ in a prescribed cycle shape ($ \text{Centralizer of } \alpha \in \Sym_{n}$).
\item Total order on $X \left( \text{ write $\alpha$ as an image list}: \begin{pmatrix}1^{\alpha} & 2^{\alpha} & \ldots & n^{\alpha} \end{pmatrix} \rightarrow \Aut(X) = 1 \right).$
\end{itemize}
\end{example}

\subsection{Groups}
\begin{definition}
Recall: a set $G$ together with a binary operation $\ast: G \times G \rightarrow G$, $\left( a, b \right) \mapsto a \ast b$ is a group if:
\begin{enumerate}
\item $\left( a \ast b \right) \ast c = a \ast \left( b \ast c \right)$ (Associativity).
\item There exists an element $e \in G$ such that $e \ast a = a = a \ast e$ for all $a \in G$ (identity).
\item For each $a \in G$ there is an element $a^{ - 1} \in G$ such that $a \ast a^{- 1} = a^{- 1} \ast a = e$ (inverse).
\end{enumerate}
\end{definition}

\begin{remark}
\begin{itemize}
\item Usually $e$ is written $1_{G}$ or 1.
\item $\left( G, \ast \right)$ is a monoid if it satisfies (1) and (2) above.
\item $\End(X)$ is a monoid.
\item Let $M$ be a monoid then, $M^{\sharp} = \left\{ a \in M : a \text{ invertible} \right\}$ is a group.
\end{itemize}
\end{remark}

\begin{example}(Examples of Groups).
\begin{enumerate}
\item $\zeta_{n} = e^{2 \pi i / 2}$, a primitive $n^{th}$ root of unity.
$C_{n} = \left\{ \zeta_{n}^{i} : i \in \mathbb{Z} \right\}$ is a cyclic group.
$$\left( C_{n}, \cdot \right) \longleftrightarrow \left( \mathbb{Z}_{n}, + \right)$$
$$\zeta_{n}^{k} \longleftrightarrow k \text{ mod } n$$
\item$\left( \mathbb{Z}, + \right)$, the infinite cyclic group.
\item Rotations and reflections of regular $n$-gons: dihedral groups.
\item Symmetric groups and general linear groups.
\end{enumerate}
\end{example}

\section{$G$-sets}
\label{sec:G-sets}
Let $G$ be a finite group.  The idea of this chapter is to study \textbf{actions} of $G$ on sets $X$.  We will see that this is a (more) convenient way to look at permutation representations.  (\textbf{Recall:} a permutation representation of $G$ is a homomorphism $\phi:G\rightarrow \Sym(X)$.)

\begin{definition}
Let $X$ be a finite set.  An \emph{action} of $G$ on $X$ is a map $X\times G\rightarrow X$, $(x, a)\mapsto x.a$ such that:
\begin{description}
\item[(A1)] $(x.a).b=x.(ab)$ for all $x\in X$, $a, b\in G$ (Composition);
\item[(A2)] $x.1=x$ for all $x\in X$ (Idleness).
\end{description}
\end{definition}

\textbf{Note:} $(A1)\nRightarrow(A2).$  For example, if $X=\{0, 1\}$ with $x.a=0$ for all $x\in X$ and $a\in G$, this satisfies $(A1)$ but not $(A2)$.

\begin{example}
We give some examples of actions.
\begin{enumerate}
\item $\Sym(X)$ acts "naturally" on $X$.  We write $x^a$ for the image of $x\in X$ under $a\in \Sym(X)$.  Then we can define an action of $\Sym(X)$ on $X$ as $x.a:=x^a$.  The product $ab$ of two permutations $a, b\in \Sym(X)$ is the result of first applying $a$ and then applying $b$.  By $(A1)$ we have $x^{ab}=x.(ab)=(x.a).b=(x^a)^b$.  For example $(12)(23)=(132)$ as we "read from the left".
\item $G$ acts on itself by right multiplication.  Let $X=G$ and $x.a:=xa$.  Then for $x, a, b\in G$ we have $(x.a).b=(xa).b=(xa)b=x(ab)=x.(ab)$ so $(A1)$ is satisfied.  Also, $x.1_G=x1_G=x$ so $(A2)$ is satisfied.
\item If we let $X=G$ and $x.a=ax$ then $(A2)$ is clearly satisfied.  For $x, a, b\in G$, $(x.a).b=(ax).b=b(ax)=(ba)x=x.(ba)\neq x.(ab)$.  In this case $(A2)$ is not satisfied, so left multiplication is not an action.\\
    However, we can modify this to make it work, as $G$ acts on $X=G$ by \textbf{inverse} left multiplication, where $x.a=a^{-1}x$.  Again, $(A2)$ is clearly satisfied.  Recall that $(ab)^{-1}=b^{-1}a^{-1}$ for any $a, b\in G$.  Hence, for $x, a, b\in G$ we have $(x.a).b=(a^{-1}x).b=b^{-1}(a^{-1}x)=(b^{-1}a^{-1})x=(ab)^{-1}x=x.(ab)$ so $(A1)$ is satisfied and we have an action.
\item $G$ acts on both sides of $X=G$ by \emph{conjugation}, i.e. $x.a=a^{-1}xa$.  To see this, let $x, a, b\in G$.  Then $(x.a).b=(a^{-1}xa).b=b^{-1}(a^{-1}xa)b=(b^{-1}a^{-1})x(ab)=(ab)^{-1}x(ab)=x.(ab)$ so $(A1)$ is satisfied.  Also, $x.1=1x1=x$ so $(A2)$ is satisfied.
\item $C_2$, the cyclic group consisting of $1$ and $a$, with $a^2=1$, acts on the divisors of $n\in\mathbb{N}$ by $d.a=n/d$.  We have $d.a^2=(d.a).a=(n/d).a=n/(n/d)=d$.
\end{enumerate}
\end{example}

\begin{remark}
Notice that an action needs no inverses, so action is a monoid concept.  If an element $a\in G$ has an inverse $a^{-1}$ then we have $(x.a).a^{-1}=x.(aa^{-1})=x.1=x$.
\end{remark}

\begin{definition}
A \emph{$G$-set} is a finite set $X$ together with an action of $G$ on $X$.  $G$-sets are permutation representations.
\end{definition}

\begin{theorem}[Action Theorem]
Suppose $X$ is a $G$-set.  Then $\Phi:G\rightarrow \Sym(X)$, $a\mapsto\tilde{a}=(x\mapsto x.a)\in \End(X)$ is a permutation representation of $G$ (on $X$).  Conversely, if $X$ is a finite set and $f:G\rightarrow \Sym(X)$ is a permutation representation then $X$ is a $G$-set with $a.x=x^{f(a)}$ for all $x\in X$, $a\in G$.

\begin{proof}
To show that $\Phi:G\rightarrow \Sym(X)$, $a\mapsto\tilde{a}=(x\mapsto x.a)\in \End(X)$ is a permutation representation of $G$, we need to show that it is a homomorphism.  Let $a, b\in G$, then $\Phi(ab)=\widetilde{ab}=x\mapsto x.(ab)=x\mapsto(x.a).b=(x\mapsto x.a)\cdot(x\mapsto x.b)=\tilde{a}\cdot\tilde{b}=\Phi(a)\Phi(b)$, so $\Phi:G\rightarrow \Sym(x)$ is a homomorphism and therefore a permutation representation.\\
Conversely, we need to show that if $f:G\rightarrow \Sym(X)$ is a permutation representation, then $X\times G\rightarrow X$, $x.a\mapsto x^{f(a)}$ is an action.  Let $x\in X$ and $a, b\in G$.  Then $(x.a).b=(x^{f(a)}).b=(x^{f(a)})^{f(b)}=x^{f(a)f(b)}=x^{f(ab)}=x.(ab)$ so $(A1)$ is satisfied.  Also, $x.1=x^{f(1)}=x^1=x$ so $(A2)$ is satisfied.  Therefore we have an action, so $X$ is a $G$-set.
\end{proof}
\end{theorem}

\begin{example}
A set $X$ is trivially a $G$-set with $x.a=x$ for $x\in X$ and $a\in G$.
\end{example}

\begin{definition}
Let $G$ and $H$ be monoids. A map $f: G \rightarrow H$ is a homomorphism of monoids if:
\begin{enumerate}
\item $f(ab) = f(a)f(b)$ for all $a, b \in G$
\item $f(1_{G}) = 1_{H}$
\end{enumerate}
\end{definition}

\begin{remark}
If $H$ is a group, $a \in G$ then $f(a) \in H$ has an inverse $f(a)^{-1}$.

$1_{h} = f(a)f(a)^{-1} = f( 1_{G} a )f(a)^{-1} = f(1_{G})f(a)f(a)^{-1} = f(1_{G}) 1_{H} = f(1_{G}).$
Also $f(a^{-1}) = f(a)^{-1}$.
\end{remark}

\begin{example}
Let $H \leq G$ be a subgroup.
$G / H = \left\{ Ha : a \in G \right\}$ the set of all right cosets of $H$ in $G$.
$G$ acts on $G / H$. $Ha.b := H(ab)$, $b \in G$. $Ha = \left\{ ha : h \in H \right\}$.
\end{example}

\begin{center}
\textbf{New actions from old}
\end{center}
Suppose $X$ is a $G$-set then:
\begin{itemize}
\item $G$ acts on $X^{k}: \left( x_{1}, \ldots, x_{k} \right) \cdot a := \left(  x_{1} a, \ldots, x_{k} a \right)$, $(A1)$ and $(A2)$.
\item $G$ acts on $2^{X} : Y \subseteq X$, $Ya := \left\{ xa : x \in Y \right\}.$
\end{itemize}

Now suppose $X$ and $Y$ are both $G$-sets.
\begin{itemize}
\item $G$ acts on $X \times Y: \left( x, y \right) \cdot a := \left( x \cdot a, y \cdot a \right) $
\item $G$ acts on $X \sqcup Y$
\end{itemize}

$z \cdot a:=
\begin{cases}
z \cdot_{x} a & \mbox{if } z \in X\\
z \cdot_{y} a & \mbox{if } z \in Y
\end{cases}$

This gives a notion of decomposability.

\begin{center}
\textbf{Orbits and Stabilizers}
\end{center}

\begin{definition}
Let $X$ be a $G$-set. $G_{x} = \left\{ a \in G : x \cdot a = x \right\}$ is the \emph{stabilizer} of $x$.
$xG = \left\{ x\cdot a : a \in G \right\}$ is the \emph{orbit} of $x$.
\end{definition}

\begin{theorem}
\begin{enumerate}
\item $G_{x}$ is a subgroup of $G$ (products and inverses of stabilizing elements do stabilize).
\item $X / G = \left\{ x \cdot G : x \in X \right\}$ is a partition of $X$ into $G$-sets.
\item $x \cdot G \cong_{G} G / G_{x}$
\end{enumerate}
\end{theorem}

\begin{center}
\textbf{G-maps, isomorphisms of G-sets and similar actions}
\end{center}

\begin{definition}
Let $X$, $Y$ be $G$-sets. A map $f : X \rightarrow Y$ is a \emph{$G$-map} if $f(x \cdot a ) = f(x) \cdot a$ for all $a \in G$ and $x \in X$.
\end{definition}

\begin{example}
$D_{12}$ acts as the symmetries of a a regular hexagon with vertices labelled from 0 to 5.
Let $X = \left\{ 0, 1, 2, 3, 4, 5 \right\}$ and $Y = \left\{ \left\{0, 3 \right\}, \left\{ 1, 4 \right\}, \left\{ 2, 5 \right\} \right\}$
Define a map $f: X \rightarrow Y$ by $x \mapsto [ x ]$
$f( x \cdot a ) = [ x \cdot a ] = [ x ] \cdot a = f( x ) \cdot a$
Thus $f$ is a $G$-map.
\end{example}

 If $f$ is a bijection we call it a $G$-isomorphism. $X$ and $Y$ are isomorphic as $G$-sets $\left( X \cong_{G} Y \right)$ if there exists a $G$-isomorphism $f: X \rightarrow Y$.

\begin{itemize}
\item A $G$-set $X$ is called \emph transitive if $X = x \cdot G$, for some/all $x \in X$.
\item Every (finite) $G$-set is a disjoint union of transitive $G$-sets.
\item Every transitive $G$-set is isomorphic to $G / H$ for some subgroup $H$ of $G$.
\item Let $H, H'\leq G$.  Then $G/H\cong_G G/H'\Leftrightarrow H'\sim_G H$ (i.e., $H'=H^a=a^{-1}Ha$ for some $a\in G$).\\
\textbf{Proof:} Let $G/H\cong_G G/H'$.  Then there is $f:G/H'\rightarrow G/H$ which is a bijection and $f(H'g)=f(H')g$.  There is $a\in G$ such that $f(H')=Ha$.  We claim that $H'=H^a$.  This is because $g\in H'\Leftrightarrow H'g=H'\Leftrightarrow Hag=f(H')g=f(H'g)=f(H')=Ha\Leftrightarrow Haga^{-1}=H\Leftrightarrow aga^{-1}\in H\Leftrightarrow g\in a^{-1}Ha=H$.  The converse of the proof is this argument in reverse.
\item Isomorphism types of transitive $G$-sets are in bijection with the conjugacy classes of $G$.
\item In particular, $G_{x.a}=G_x^a$.
\end{itemize}

\begin{example}
\label{D8}
Let $G=D_8$ which is the group of all symmetries of the square:
$$\xymatrix{^1{\bullet} \ar@{-}[r] \ar@{-}[d] & {\bullet}^2 \\ _4{\bullet} & {\bullet}_3 \ar@{-}[l] \ar@{-}[u]}$$
i.e., $G=\langle\gamma,\beta,\alpha\rangle$ where $\gamma=(1,2,3,4)$ is a rotation, $\beta=(1,2)(3,4)$ is a reflection without fixed points, and $\alpha=(1,3)$ is a reflection with fixed points.  The subgroup lattice of $D_8$ is:
$$\xymatrix{&& G \ar@{-}[dl] \ar@{-}[d] \ar@{-}[dr]\\
& \langle\beta,\gamma^2\rangle \ar@{-}[dl] \ar@{-}[d] \ar@{-}[dr] & \langle\gamma\rangle \ar@{-}[d] & \langle\alpha,\gamma^2\rangle \ar@{-}[dl] \ar@{-}[d] \ar@{-}[dr] \\
\langle\beta'\rangle \ar@{-}[drr] & \langle\beta\rangle \ar@{-}[dr] & \langle\gamma^2\rangle \ar@{-}[d] & \langle\alpha\rangle \ar@{-}[dl] & \langle\alpha'\rangle \ar@{-}[dll] \\
&& 1}$$
$G$ acts on $X=\{(a,b)\in\mathbb{Z}^2:\Size{a},\Size{b}\leq2\}$ as follows:
$$\xymatrix{ {\alpha'} \ar@{-}[ddddddrrrrrr] &&& {\beta}\ar@{-}[dddddd] &&& \\
& {\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
& {\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
{\beta'} \ar@{-}[rrrrrr] & {\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} & \\
& {\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
& {\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
{\alpha} \ar@{-}[uuuuuurrrrrr] &&&&&&}$$
where $\alpha, \alpha', \beta, \beta'$ are reflections in the lines labelled as such, and $\gamma$ is a rotation.  Note that the point in the centre of the diagram is not moved by any of the permutations.  The points on the reflecting lines are moved by everything.  Using this, we can decompose $X$ into orbits:
$$X\cong G/G\cup G/1\cup 2G/\langle\alpha\rangle\cup 2G/\langle\beta\rangle.$$
\end{example}

Write $[X]$ for the isomorphism type of $X$, i.e., the class of $G$-sets isomorphic to $X$.  Denote $B^+(G)=\{[X]:X$ finite $G$-set$\}$.  then define $B(G)$ as the abelian group generated by $B^+(G)$ subject to the relations
$$[X\sqcup X']-[X]-[X']=0$$
for all $[X], [X']\in B^+(G)$.  In $B(G)$ we have
$$[X\sqcup X']=[X]+[X'].$$
If $\{H_1,\ldots,H_m\}$ is a transversal of the conjugacy classes of subgroups of $G$ then $\{[G/H_1],\ldots,[G/H_m]\}$ is a $\mathbb{Z}$-basis of $B(G)$, i.e., for $x\in B(G)$, $x=\sum_{i=1}^m a_i[G/H_i]$ for unique coefficients $a_i\in\mathbb{Z}$.  (As an additive group, $B(G)\cong\mathbb{Z}^m$.)\\
Define a multiplication on $B(G)$ as
$$[X]\cdot [X']=[X\times X'].$$
This multiplication is well-defined, associative, distributive, and commutative.  Hence, $B(G)$ is a commutative ring with unit $[G/G]$, called the \emph{Burnside ring of $G$}.

\begin{lemma}
Let $R$ be a commutative ring and $D$ an integral domain.  Then any set of distinct ring homomorphisms $\lambda_i:R\rightarrow D$ is linearly independent over $D$.
\end{lemma}

What sort of ring is $B(G) = \left\langle [G/H] : H \leq G \right\rangle$?
$R = B(G)$ and $D = \mathbb{Z}$

\textbf{special case:}
Let $R = V: \mathbb{C}$-algebra: $\mathbb{C}$-vectorspace with a notion of multiplication defined, e.g. $n \times n$ matrices.
Let $D$ be the field of complex numbers i.e. $D = \mathbb{C}$. $C$-homomorphisms $V \rightarrow \mathbb{C} = V^{\ast}$ the duel space of $V$. Ring-homomorphisms: $V \rightarrow \mathbb{C}$ are those $\lambda \in V^{\ast}$ which addtionally satisfy $\lambda (ab) = \lambda(a) \lambda(b)$ and $\lambda(1_{V}) = 1_{\mathbb{C}}$.

Linear Algebra: $V^{\ast}$ has a distinguished basis consisting of ring homomorphisms, $\lambda_{1}, \ldots, \lambda_{n}$. $\Rightarrow$ basis of $V: e_{1}, \ldots, e_{2}$, $\lambda_{i} (e_{j}) = \delta_{ij} = \begin{cases}
                                                                                                                                             1 & \mbox{if } i = j;\\
                                                                                                                                             0 & \mbox{otherwise}\\
                                                                                                                                          \end{cases}.$

Check that $e_{i}^{2} = e_{i}$:
$v \in V: v = \sum{\alpha_{i}}{e_{i}}.$
$\lambda_{j} (v) = \alpha_{j}.$
$e_{i}^{2} = \sum{\alpha_{i}}{e_{i}}.$
$\lambda_{j} (e_{i}^{2}) = \lambda_{j} (e_{i}) \lambda_{j} (e_{i})$
$ = \delta_{ij}^{2} = \delta_{ij}$ since $i = j$, $\delta_{ij} = 1.$

Now check if $e_{i} e_{k}$ if $i \neq k$.
$\lambda_{j} (e_{i} e_{k}) = \lambda_{j} (e_{i}) \lambda_{j} (e_{k}) = \delta_{ij} \delta_{ik} = \begin{cases}
                                                                                                                                                            1 & \mbox{if } i = j= k\\
                                                                                                                                                            0 &\mbox{otherwise}\\
                                                                                                                                                         \end{cases}$
$\Rightarrow e_{i} e_{k} = 0$.

Note: $\sum{e_{i}} = 1$. The set of $\left\{ e_{i} \right\}$ form a complete set of orthogonal idempotents of $V$. Let $a = \sum{\alpha_{i}}{e_{i}}$ and $b = \sum{\beta_{i}}{e_{i}}$ then $ab = \sum{\alpha_{i} \beta_{i}}{e_{i}}$. $e_{i}$ is the standard basis of $V$. $a = \sum{\alpha_{i}}{e_{i}} = \left( \alpha_{1}, \alpha_{2}, \ldots, \alpha_{n} \right)$.

$V \cong \mathbb{C}^{n}$ with componentwise addition and multiplication.

\begin{lemma}
$R$ a commutative ring, $D$ an integral domain. Then any set of distinct ring homomorphisms $\lambda_{i} : R \rightarrow D$ is linearly independent over $D$.
\end{lemma}

\begin{proof}
Suppose $\sum_{i = 1}^{m} {a_{i}}{\lambda_{i}} = 0$, $a_{i} \in D \setminus \left\{ 0 \right\}$ and $m$ chosen to be minimal.
$m = 1$ is impossible. Take $a_{1} \lambda(r) = 0$ which implies $a = 0$ or $\lambda(r) = 0$ which cannot happen. Pick $y \in R$ such that $\lambda_{1} (y) \neq \lambda_{2} (y)$. Then for all $x \in R$, $0 =  \sum^{m}_{i = 1} {a_{i}}{\lambda_{i} (xy)} = \sum^{m}_{i = 1} {a_{i}} {\lambda_{i} (x) \lambda_{i} (y)}$. $\sum^{m}_{i = 2} \underbrace{a_{i} \left(\lambda_{i}(y) - \lambda_{i} (y) \right)}_{a^{'}_{i}} \lambda_{i} (x) = 0$, $a^{'}_{2} = 0$. This is a relation with strictly fewer terms, a contradiction since $m$ was chosen to be minimal.
$$\sum^{m}_{i = 1} { a_{i}} {\lambda_{i} (y) \lambda_{i} (x)} - \lambda_{1} (y) \sum^{m}_{i = 2} {a_{i}}$$
$$\underbrace{\sum^{m}_{i = 1} {a_{i}}{\lambda_{i}(y) \lambda_{i}(x)}}_{ = 0} - \lambda_{1}(y) \underbrace{\sum^{m}_{i = 1} {a_{i}}{\lambda_{i}}}_{ = 0} (x)$$
\end{proof}

Find $\lambda: B(G) \rightarrow \mathbb{Z}$
$$\lambda_{1}: [x] \mapsto \# X = \Size{X}$$
$$[y] \mapsto \# Y$$
$$[x] \cdot [y] = [x \times y] \mapsto \# \left(X \times Y \right)$$

More: $H \leq G$: let $X$ be a $G$-set,
$$\Fix_{x} \left( H \right) = \left\{ x \in X : x \cdot h = x \text{ for all } h \in H \right\}$$
Claim: $\Fix_{X \times Y} (H) = \Fix_{X} (H) \times \Fix_{Y} (H)$
$$\Rightarrow \Size{\Fix_{X \times Y} (H)} = \Size{\Fix_{X}(H)} \cdot \Size{\Fix_{Y} (H)}$$
$$\Rightarrow \lambda_{H}:= [X] \mapsto \Size{\Fix_{x}(H)}$$
$$\lambda_{H} = \lambda_{H^{'}} \Leftrightarrow H \sim_{G} H^{'}$$

\begin{definition}
$\lambda_H([X])$ is called the \emph{mark} of $H$ on $X$.  The \emph{table of marks} of $G$ is the matrix $(\lambda_H([G/K]))_{K, H\in\mathcal{S}}$, where $\mathcal{S}=\{H_1,\ldots,H_l\}$ is a transversal of conjugacy classes of subgroups of $G$.  We denote the table of marks of $G$ by $M(G)$.
\end{definition}

For $K, H\leq G$ we have
$$\lambda_H([G/K])=\Size{\Fix_{G/K}(H)}=|size{N_G(K):K}\cdot\sharp\{K^g\geq H, g\in G\}.$$
In particular, for $K=H$,
$$\underbrace{\lambda_H([G/H])}_{\textrm{diagonal entry of table of marks}}=\Size{N_G(H):H}=\underbrace{\Size{G:H}}_{\lambda_1}/\underbrace{\Size{G:N_G(H)}}_{\sharp\textrm{ conjugates of }H}.$$

\begin{example}
Let $G$ be the dihedral group of order 8, i.e. $G = D_{8}$ . Once again the subgroup lattice is:
$$\xymatrix{&& G \ar@{-}[dl] \ar@{-}[d] \ar@{-}[dr]\\
& \langle\beta,\gamma^2\rangle \ar@{-}[dl] \ar@{-}[d] \ar@{-}[dr] & \langle\gamma\rangle \ar@{-}[d] & \langle\alpha,\gamma^2\rangle \ar@{-}[dl] \ar@{-}[d] \ar@{-}[dr] \\
\langle\beta'\rangle \ar@{-}[drr] & \langle\beta\rangle \ar@{-}[dr] & \langle\gamma^2\rangle \ar@{-}[d] & \langle\alpha\rangle \ar@{-}[dl] & \langle\alpha'\rangle \ar@{-}[dll] \\
&& 1}$$

\begin{table*}[h]
    \centering\
    \begin{tabular}{|c | c  c  c  c  c  c  c  c |}
    \hline
    $G/ 1$ & 8 & &  & & & & & \\
    $G / \left\langle \alpha \right\rangle$ & 4 & 2& & & & & & \\
    $G / \left\langle \beta \right\rangle$  & 4 & 0 & 2 & & & & & \\
    $G / \left\langle \gamma^{2} \right\rangle$ & 4 & 0 & 0 & 4 & & & & \\
    $G / \left\langle \gamma \right\rangle$ & 2 & 0 & 0 & 2 & 2 & & & \\
    $G / \left\langle \alpha, \gamma^{2} \right\rangle$ & 2 & 2 & 0 & 2& 0 & 2 & & \\
    $G / \left\langle \beta, \gamma^{2} \right\rangle$ & 2 & 0 & 2 & 0 & 2 & 0 & 2 & \\
    $G / G$ & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
    \hline
    $ $ & $1$ & $ \left\langle \alpha \right\rangle$ & $\left\langle \beta \right\rangle$ & $\left\langle \gamma^{2} \right\rangle$ & $\left\langle \gamma \right\rangle$ & $\left\langle \alpha, \gamma^{2} \right\rangle$ & $\left\langle \beta, \gamma^{2} \right\rangle$ & $G$\\[1ex]
    \hline
    \end{tabular}
\end{table*}

This is the base change matrix between the standard basis of $\mathbb{Z}^{m}$ and the basis of transitive $G$-sets of $B(G)$.
\end{example}

\begin{theorem}[Burnside]
Define $\beta:B(G)\rightarrow\bigoplus_{H\in\mathcal{S}}\mathbb{Z}$, $[X]\mapsto(\lambda_H([X]))_{H\in\mathcal{S}}$.  Then $\beta$ is an injective ring homomorphism.

\begin{proof}
Clearly $\beta$ is a ring homomorphism.  For $x\in B(G)$, $x=\sum_{H\in\mathcal{S}}a_H[G/H]$.  Then $\beta(x)=(a_H)_{H\in\mathcal{S}}\cdot M(G)$.  The matrix $M(G)$ is lower triangle $\Rightarrow$ the diagonal is not zero $\Rightarrow$ the determinant is not zero $\Rightarrow\ M(G)$ is invertible.  It follows that $\beta$ is injective.
\end{proof}
\end{theorem}

We return to Example \ref{D8}, with $G=D_8$ acting on $X=\{(a,b)\in\mathbb{Z}^2:\Size{a},\Size{b}\leq2\}$.
$$\xymatrix{{\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
{\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
{\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
{\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet} \\
{\bullet} & {\bullet} & {\bullet} & {\bullet} & {\bullet}}$$
We want to write $X=\sum a_H[G/H]$ so we need to find the $a_H$.  We have $\beta(X)=(25,5,5,1,1,1,1,1)$.  This is the impression of $G$ on $X$.  Using this, we can write:
$$[X]=[G/G]+[G/1]+2[G/\langle\alpha\rangle]+2[G/\langle\beta\rangle].$$

\begin{center}
\textbf{Summary}
\end{center}
\begin{itemize}
\item $G$-sets are unions of transitive ones.
\item Isomorphism types of transitive $G$-sets are in bijection with conjugacy classes of subgroups.
\item Isomorphism types form a ring $B(G)$ with respect to $\sqcup$ and $\times$.
\item $\beta:B(G)\rightarrow\mathbb{Z}^m$ is a ring homomorphism with the table of marks $M(G)$ as its matrix, relative to the basis $\{[G/H], H\in\mathcal{S}\}$ of $B(G)$ and the standard basis of $\mathbb{Z}^m$.
\item $\beta$ is injective, but is not surjective in general.
\item $\beta$ has finite co-kernel $\mathbb{Z}^m/im(\beta)$ of size $\prod_{H\in\mathcal{S}}\Size{N_G(H):H}$
\end{itemize}


\section{GAP}
GAP is a system for computational algebra, with an emphasis on group theory.  It provides a programming language which is easy to learn and understand, so it doesn't get in the way of the mathematics.  GAP is an interactive system. It continuously executes a read evaluate print loop.\\

To begin, typing \verb"gap" at the prompt of your operating system followed by the return key will start GAP and will bring up its own prompt\\
\verb"gap>"\\
where you can type in further commands.  To end a GAP session, type in \verb"quit;".

\begin{center}
\textbf{Permutations}
\end{center}

Permutations in GAP are represented as disjoint cycles:\\
\verb"gap> (1,2,3)(6,7)"\\
and can be multiplied:\\
\verb"gap> (1,2,3)(6,7)*(2,3,5)(4,7);"\\
This can also be written as:\\
\verb"gap> a:=(1,2,3)(6,7)"\\
\verb"gap> b:=(2,3,5)(4,7);"\\
\verb"gap> a*b;"\\

Actions act from the right in GAP, using the \verb"^" notation, which we say as "under".  For example,\\
\verb"gap> 2^(1,2,3);"\\
\verb"3"\\

\begin{center}
\textbf{Lists}
\end{center}
A list is a collection of objects separated by commas and enclosed in brackets.\\
\verb"gap> l=[2,3,1,4,5,7,6];"\\
Lists in GAP will grow and shrink on command.  We can add to a list:\\
\verb"gap> a:=(1,2,3)(6,7);"\\
\verb"gap> list:=[()];"\\
\verb"gap> a in list;"\\
\verb"false"\\
\verb"gap> Add(list, a);"\\
\verb"gap> list;"\\
\verb"[(), (1,2,3)(6,7)]"\\
The command \verb"PermList(l)" will give the permutation that moves points as described by the list \verb"l".\\
\verb"gap> PermList(l);"\\
\verb"(1,2,3)(6,7)"\\
We can apply a function to a list.
\verb"gap> List([1..7], i->i^(1,2,3)(6,7));"\\
\verb"[2,3,1,4,5,7,6]"\\
Note that \verb"[1..7]" will give the list of numbers ranging between 1 and 7.  The second argument \verb"i->i^(1,2,3)(6,7)" will apply this function to each thing in the list, returning the resulting list of values.  We could also name the function:\\
\verb"gap> f:=i->i^(1,2,3)(6,7);"\\
\verb"gap> List([1..7], f);"\\
\verb"[2,3,1,4,5,7,6]"\\

We can also form sets in GAP.  A set is a sorted, duplicate-free list.

\begin{center}
\textbf{Loops}
\end{center}
Given a list of permutations we can form their product by means of a for loop instead of writing down the product explicitly.\\
\verb"gap> a:=(1,2,3)(6,7);"\\
\verb"gap> list:=[(),a];"\\
\verb"gap> for b in list do"\\
\verb">      c:=b*a";\\
\verb">      if not c in list then Add(list, c);"\\
\verb">      fi;"
\verb">    od;"\\
If we then type in the command \verb"list" we will get a list of all the powers of $a$, i.e., $<a>$.\\

The \verb"for" loop has the syntax:\\
\verb"for" \emph{var} \verb"in" \emph{list} \verb"do" \emph{statements} \verb"od;"\\
The effect of the \verb"for" loop is to execute the \emph{statements} for every element of the \emph{list}. A \verb"for" loop is a statement and therefore terminated by a semicolon. The list of statements is enclosed by the keywords \verb"do" and \verb"od" (the reverse of \verb"do"). A \verb"for" loop returns no value so we need to ask for this explicitly.

\begin{center}
\textbf{Groups}
\end{center}

Groups are represented by a list of generating elements (permutations, matrices, abstract generators).  They are constructed by the \verb"Group" function.  To create the group generated by the permutations $a=(1,2,5,6)(3,8,7,4)$ and $b=(1,3,5,7)(2,4,6,8)$ we type:\\
\verb"gap> a:=(1,2,5,6)(3,8,7,4);"\\
\verb"gap> b:=(1,3,5,7)(2,4,6,8);"\\
\verb"gap> g8:=Group(a,b);"\\
\verb"Group([ (1,2,5,6)(3,8,7,4), (1,3,5,7)(2,4,6,8)" ])\\
The function \verb"Size" can be used to determine the number of elements in a group and the function \verb"Elements" lists all the elements explicitly.  The \verb"Elements" function should be avoided when working with bigger groups.\\
\verb"gap> Size(g8);"\\
\verb"8"\\
\verb"gap> Elements(g8);"\\
\verb"[ (), (1,2,5,6)(3,8,7,4), (1,3,5,7)(2,4,6,8), (1,4,5,8)(2,7,6,3),"\\
\verb"(1,5)(2,6)(3,7)(4,8), (1,6,5,2)(3,4,7,8), (1,7,5,3)(2,8,6,4),"\\
\verb"(1,8,5,4)(2,3,6,7) ]"\\
We can ask other question about the group using commands like \verb"IsFinite" and \verb"IsAbelian".  We can ask if another group \verb"sub" is a subgroup of \verb"g8" by typing \verb"IsSubgroup(g8, sub)", remembering to write the bigger group first.

\begin{center}
\textbf{Orbits and Stabilizers}
\end{center}

The orbit of a point \verb"x" is constructed by the function \verb"Orbit".  The stabilizer of a point \verb"x" is constructed by the function \verb"Stabilizer".  Both functions take the group and the point $x$ as arguments.  For example,\\
\verb"gap> grp:=Group((1,2,3,4),(1,4));"\\
\verb"gap> Orbit(grp,2);"\\
\verb"gap> Stabilizer(grp,2);"\\
These functions can also take an optional third argument to specify a non-standard  action.  The default action for permutation groups is \verb"OnPoints".  This is a GAP function which could have been defined as\\
\verb"OnPoints:= function(x, a) return x^a; end;"\\
It takes a point \verb"x" and a permutation \verb"a" as its argument and returns the image \verb"x^a" of the point under the permutation.  Other actions which are available as GAP functions are:
\verb"OnSets:= function(Y, a) return Set(List(Y, x->x^a)); end;"\\
\verb"OnTuples:= function(list, a) return List(list, x->x^a); end;"\\
So these actions functions are extra arguments which indicate how a group acts on a given set.  Using the group \verb"g8" defined before, we have\\
\verb"gap> Orbit(g8, [1,2,5,6], OnSets);"\\
\verb"[[1,2,5,6],[3,4,7,8]]"\\
\verb"gap> Orbit(g8, [1,2,5,6], OnTuples);"\\
\verb"[ [1,2,5,6], [2,5,6,1], [3,4,7,8], [5,6,1,2], [4,7,8,3], [8,3,4,7],"\\
\verb"[6,1,2,5], [7,8,3,4]]"

\begin{center}
\textbf{Orbit Algorithm}
\end{center}

The orbit Algorithm computes for a given monoid $G$, generated by a subset $A$ of a monoid $M$ acting on a set $X$, the orbit $x.G$ of a point $x\in X$ as follows:\\
\begin{enumerate}
\item $O\leftarrow (x)$
\item for $y\in O$:
\item \ \ for $a\in A$:
\item \ \ \ \ $z\leftarrow y.a$
\item \ \ \ \ if $z\not\in O$: append $z$ to the list $O$
\item return $O$.
\end{enumerate}
We can enter the orbit algorithm as a GAP function as follows:\\
\verb"myOrbit:= function(A, x, under)"\\
\verb"   local a, y, z, orbit;"\\
\verb"   orbit:= [x];"\\
\verb"   for y in orbit do"\\
\verb"      for a in A do"\\
\verb"         z:= under(y, a);"\\
\verb"         if not z in orbit then Add(orbit, z); fi;"\\
\verb"   od; od;"\\
\verb"   return orbit;"\\
\verb"end;"

\begin{center}
\textbf{Extended Orbit Algorithm}
\end{center}

Given $A \subseteq \Sym(X)$, $x \in X$ compute $\theta = x.G$ for $G = \left\langle A \right\rangle$ and transversal of $G_{x}$ in $G$.
\begin{enumerate}
\item $O \leftarrow (x); t_{x} = id_{x}$
\item for $y \in O$
\item \ \ for $a \in A$
\item \ \ \ \ $z \leftarrow y \cdot a$
\item \ \ \ \ if $z \not\in O$
\item \ \ \ \ append $z$ to the list $O$; $t_{x} = t_{y \cdot a}$
\item return $O$ and $T = \left( t_{y} : Y \in O \right)$
\end{enumerate}

Now every point in $\theta$ has one arrow leaving each generator:

action graph: vertice $\leftrightarrow \theta$
arrows: $y \stackrel{a}{\rightarrow} y \cdot a$, $y \in O$, $a \in A$
$B = \left\{ t_{y} \cdot a \cdot t_{y \cdot a}^{- 1} : y \in \theta, a \in A \right\}$

\begin{theorem}
$G_{x} = \left\langle B \right\rangle$
\end{theorem}

\begin{proof}
$B \subseteq G_{x}$ - by construction.

$G_{x} \subseteq \left\langle B \right\rangle$
$G_{x} = \left\{ t_{y} \cdot a \cdot t_{y \cdot g}^{ - 1 } : y \in \theta, g \in G \right\}$

$y \in G_{x}$ can be written as a product of things in $B$. $g \in G = \left\langle A \right\rangle$, $g = a_{1} \cdot a_{2} \ldots a_{q}$, $a_{i} \in A$. Induction on $q$: if $q = 0$ then $g = id_{x}$.
If $q > 0$, $t_{y \cdot g} \cdot t_{y \cdot g}^{- 1} = t_{y \cdot a_{1} \ldots a_{q}} \cdot t_{y \cdot g}^{ - 1}$
$ = \underbrace{t_{y} \cdot a_{1} \cdot t_{y \cdot a_{1}}}_{ \in B} \cdot \overbrace{t_{y \cdot a_{1}} \cdot \underbrace{a_{2} \ldots a_{q}}_{\text{length } \left( q - 1\right) } \cdot t_{y \cdot g}^{ - 1}}^{\text{these can be written as elements of } B}$
\end{proof}

\begin{center}
\textbf{Schreier--Sims Algorithm}
\end{center}

Input: $A \subseteq \Sym(X)$. Output: $\Size{G}$ for $G = \left\langle A \right\rangle$.

\begin{enumerate}
\item If $A \subseteq \left\{ id_{x} \right\}$: return 1
\item Choose $x \in X$ such that $x \cdot a \neq x$ for some $a \in A$
\item Apply the extended orbit algorithm to $A \cdot x$ to compute orbit $O = x \cdot \left\langle A \right\rangle$ and transversal $T = \left( t_{y} : y \in O \right)$
\item $B \leftarrow$ as in Schier generators.
\item recursively compute $\Size{ \left\langle B \right\rangle }$.
\item return $\Size{\left\langle B \right\rangle} \cdot \Size{O}$
\end{enumerate}

Start with generators $A$ for $G$ Schier-Sims, generators $B$ for $G_{x}$.

$A$ Sims table for G. i.e. a base ( a list of points chosen to be stabilized) and strong generating ( disjoint union of the $T_{i}$) for $G$.

$$G = G_{x_{1}} \cdot T_{1}$$
$$G_{x_{1}} = G_{x_{1} \cdot x_{2}} \cdot T_{2}$$
$$ \vdots$$
$$G = T_{i} \cdot T_{i - 1} \cdot \ldots \cdot T_{2} \cdot T_{1}$$

Thus each $g \in G$ can be written in a unique way as a product:
$$g = t_{i} \cdot t_{i - 1} \cdot \ldots \cdot t_{2} \cdot t_{1}, \quad t_{i} \in T_{i}$$
 $\rightarrow$ Compute the size of $\| G \|$. Decide membership $g \in G$. Loop over elements of $G$ pick a random element from $G$ uniformly find (generators for) intersection with other groups.

Let $X$ and $Y$ be $G$-sets, then $X \sqcup Y$ and $X \times Y$ are $G$-sets. Denote by $[X]$ the isomorphism type of a $G$-set $X$ (e.g. $[X] = [G/G_{x}]$ if $X \cong_{G} G/G_{x}$). Then the set of all isomorphism types of $G$-sets can be regarded as a ring with addition. $$[X] + [Y] = [X \sqcup Y]$$ $$[X] \cdot [Y] = [ X \times Y]$$

\section{Matrix Representations}

Representing groups as automorphisms of vector spaces. $\alpha \in Aut(X)$, $\alpha: X \rightarrow X$ specify all $\alpha (x)$ if $X$ is a set. $X = V$ sufficient to specify $\alpha (v)$ for $v$ in a basis of $V$. Now we must distinguish between $F$-representations and matrix representations over $F$, where $F$ is a field.

Let $G$ be a group, $F$ a field and $V$ an $F$- vector space of dimension $dim(V) = n$.

$GL(V) := Aut_{F} (V) = End_{F}^{\ast} (V)$, where $End_{F} (V) = Hom_{F} (V, V)$. Write $\varphi \in Aut_{F} (V)$ on the right: $v \cdot \varphi = v^{\varphi}$ (rather than $\varphi (v)$). Choose a basis $B = \left( v_{1}, \ldots, v_{n} \right)$ of $V$. $\varphi \in End_{F} (V)$ the matrix $[ \varphi ]_{B} = [ a_{i j} ] \in F^{n \times n}$ defined by $v_{i}^{\varphi}  = \sum_{j = 1}^{n} {a_{ij}}{v_{j}}$, where $i = 1, \ldots, n$ is the matrix of $\varphi$ relative to $B$. Then $[ \  ]_{B} : GL(V) \rightarrow GL_{n} (F) = \left( F^{n \times n} \right)^{\ast}$ defined by $\varphi \mapsto [ \varphi ]_{B}$ is an isomorphism of groups: $[ \varphi \cdot \psi ]_{B} = [ \varphi ]_{B} [ \psi ]_{B}$. $v \in V: [ v ]_{B} = \underbrace{\left( a_{1}, \ldots, a_{n} \right)}_{\text{row vectors}}$ if $v = \sum{a_{i}}{v_{i}}$. $\left[ v^{\varphi} \right]_{B} = [v]_{B} [ \varphi ]_{B}$ is the row convention.

\begin{definition}
An $F$-representation of $G$ is a homomorphism $G \rightarrow GL(V)$. A matrix representation of $G$ over a field $F$ is a homomorphism where $dim(V) = n$ is the degree of the representation.
\end{definition}

We prefer matrices for computational purposes. Given an $F$-representation $\delta: G \rightarrow GL(V)$, and a basis $B$ of $V$ then $[ \  ]_{B} \circ \delta := \delta_{B}$, ($ \delta_{B} (g) = \left[ \delta (g) \right]_{B}$ ) is a matrix representation of $G$.

$\delta$, $\delta^{'}: G \rightarrow GL_{n} (F)$ are equivalent if there exists $T \in GL_{n} (F)$ such that $\delta^{'} (g) = T^{- 1} \delta (g) T$.

$\delta$, $\delta^{- 1}: G \rightarrow GL(V)$ are equivalent if there exists $\varphi \in GL(V)$ such that $\delta^{- 1} (g) = \varphi^{- 1} \delta (g) \varphi \Rightarrow$ the equivalence class of $\delta_{B}$ does not depend on the choice of $B$.

\begin{example}
$G = D_{8} = \left\langle \gamma, \alpha, \beta \right\rangle$. Where $\gamma$ is a rotation through 90 degrees, $\alpha$ is a reflection through the main diagonal axis and $\beta$ is a reflection about the horizontal axis. $\beta$ is a word n $\alpha$ and $\gamma$. So $D_{8} = \left\langle \gamma, \alpha \right\rangle$. Let $A$ and $B$ be matrices such that:

\begin{equation*}
\mbox{\textbf{A}} = \left(
\begin{array}{cc}
     0 & 1 \\
    - 1 & 0 \\
\end{array}
\right)
\end{equation*}

\begin{equation*}
\mbox{\textbf{B}} = \left(
\begin{array}{cc}
     1 & 0 \\
     0 & - 1 \\
\end{array}
\right)
\end{equation*}

Now $A^{4} = B^{2} = I_{2}$ and $B^{- 1} A B = A^{- 1}$. It should also be noted that $\gamma^{4} = \alpha^{2} = id$ and $\alpha^{-1} \gamma \alpha = \gamma^{- 1}$, this is the group presentation of $D_{8}$ i.e.; $$ D_{8} = \left\langle \alpha, \gamma : \gamma^{4} = \alpha^{2} = id, \alpha^{-1} \gamma \alpha = \gamma^{-1} \right\rangle$$

$D_{8}$ is the quotient of the free group generated by $\alpha$ and $\gamma$, i.e. all words in the alphabet $\left\{ \alpha, \gamma, \alpha^{- 1}, \gamma^{- 1} \right\}$, (modulo $\alpha \alpha^{- 1} = 1, \alpha^{- 1} \alpha = 1, \gamma \gamma^{- 1}, \gamma^{- 1} \gamma = 1$, where 1 is the empty word), with the normal subgroups generated by relations written as relators $ \gamma^{4}, \alpha^{2}, \alpha^{- 1} \gamma \alpha \gamma^{- 1}$.
$$D_{8} = \left\{ 1, \gamma, \gamma^{2}, \gamma^{3}, \alpha, \gamma \alpha, \gamma^{2} \alpha, \gamma^{3} \alpha \right\}$$
$$\varphi : G \rightarrow GL_{2} (F)$$
$$\gamma \mapsto A$$
$$\alpha \mapsto B$$
$\varphi$ is a homomorphism, since $B$, $A$ satisfy the relations of $\left\langle \gamma, \alpha \right\rangle = D_{8}$. This means that $D_{8}$ isomorphic it the following group of matrices;

$$\Tiny{\left\{  \left(
\begin{array}{cc}
     1 & 0 \\
     0 & 1 \\
\end{array}
\right),  \left(
\begin{array}{cc}
     0 & 1 \\
    - 1 & 0 \\
\end{array}
\right), \left(
\begin{array}{cc}
     - 1 & 0 \\
     0 & -1 \\
\end{array}
\right),  \left(
\begin{array}{cc}
     0 & - 1 \\
    1 & 0 \\
\end{array}
\right), \left(
\begin{array}{cc}
     1 & 0 \\
     0 & - 1 \\
\end{array}
\right), \left(
\begin{array}{cc}
     - 1 & 0 \\
     0 & 1 \\
\end{array}
\right), \left(
\begin{array}{cc}
     0 & 1 \\
    - 1 & 0 \\
\end{array}
\right),  \left(
\begin{array}{cc}
     0 & 1 \\
    1 & 0 \\
\end{array}
\right)   \right\}} $$

\end{example}

\begin{example}
$G \rightarrow GL_{n} (F)$ defined by $g \mapsto I_{n}$. If $n = 1$ this is called the trivial representation.
\end{example}

In general $ker(\delta) = \left\{ g \in G : \delta (g) = I_{n} \right\}$. $\delta: G \rightarrow GL_{n} (F)$ is said to be \emph{faithful} if $ker (\delta) = \left\{ 1 \right\}$.

\begin{center}
\textbf{$FG$-modules}
\end{center}

Let $\delta:G\rightarrow GL_n(F)$ be a matrix representation and $V=F^n$ a row space.  Then for $u, v\in V$, $g, h\in G$ and $\lambda\in F$ we have:
\begin{itemize}
\item $v\delta(gh)=v\delta(g)\delta(h)$ since $\delta$ is a homomorphism;
\item $v\delta(1)=v$ since $\delta(1)=I_n$;
\item $(\lambda v)\delta(g)=\lambda(v\delta(g))$;
\item $(v+u)\delta(g)=v\delta(g)+u\delta(g)$.
\end{itemize}

\begin{definition}
Let $G$ be a group.  An $F$-vector space $V$ together with an (action) map $V\times G\rightarrow V,\ (v, g)\mapsto v.g$ is an \emph{$FG$-module} if
\begin{description}
\item[(A1)] $v.(gh)=(v.g).h$ (Composition)
\item[(A2)] $v.1=v$ (Idleness)
\item[(L1)] $(\lambda v).g=\lambda(v.g)$
\item[(L2)] $(u+v).g=u.g+v.g$
\end{description}
\end{definition}

\noindent An $FG$-module is a $G$-set where $G$ acts as linear transformations.\\

\begin{theorem}[Linear Action Theorem]
$FG$-modules "are" matrix representations in the following way:
\begin{enumerate}
\item Suppose $V$ is an $FG$-module of dimension $dim\ V=n$.  Let $B$ be a basis of $V$.  Then the map $\delta:G\rightarrow GL_n(F),\ g\mapsto [g]_B$, is a matrix representation of $G$ (on $V$).
\item Conversely, if $\delta:G\rightarrow GL_N(F)$ is a matrix representation of $G$ and $V$ is an $F$-space with basis $B$, $dim\ V=n$, then $V$ $FG$-module with action defined as $[v.g]_B=[v]_B\delta(g)$.
\end{enumerate}

\begin{proof}
\begin{enumerate}
\item We need to show that $[\ ]_B:G\rightarrow F^{n\times}$ is a homomorphism and that $[G]_B\subseteq GL_n(F)$.  By $(L1)$ and $(L2)$, $g,h\in G$ act as linear transformations on $V$.  The matrices $[g]_B$ and $[h]_B$ are their matrices relative to $B$.  By $(A1)$, $gh$ acts as the composition of the linear maps $g$ and $h$.  Then by Linear Algebra, $[gh]_B=[g]_B[h]_B$ so we have a homomorphism.  In particular, $I_n=[1]_B=[g]_B[g^{-1}]_B$ so $[g]_B\in GL_n(F)$.
\item Let $V=F^n$ and let $B=(e_1,\ldots,e_n)$ be the standard basis.  Then $[v]_B=v$ for all $v\in V$.  Define an action by $v.g=v\delta(g)\in V$ (matrix multiplication).
    \begin{description}
    \item[(A1)] $v.g).h=(v\delta(g))\delta(h)=v(\delta(g)\delta(h))=v\delta(gh)=v.(gh)$.
    \item[(A2)] $v.1=v\delta(1)=vI_n=v$.
    \item[(L1)+(L2)] Clear.
    \end{description}
    In general, choose a basis $B=\{v_1,\ldots,v_n\}$ of $V$.  Then $[\ ]_B:V\rightarrow F^n$ is an $FG$-module isomorphism with inverse $(a_1,\ldots,a_n)\mapsto\sum a_i v_i$.  $F^n$ is an $FG$-module which implies $V$ is an $FG$-module.
\end{enumerate}
\end{proof}
\end{theorem}

\begin{example}
Let $G=D_8=\langle\gamma,\alpha:\gamma^4=\alpha^2=1,\gamma^{\alpha}=\gamma^{-1}\rangle$ and let
$$\delta:\gamma\mapsto\left(\begin{array}{cc}
0 & 1 \\ -1 & 0 \\
\end{array}\right),
\alpha\mapsto\left(\begin{array}{cc}
1 & 0 \\ 0 & -1 \\
\end{array}\right).$$
Then $V=F^2$ is an $FG$-module with $v.g=v\delta(g).$  For example, $(1,0).\gamma=(0,1)$ and $(0,1).\gamma=(-1,0)$.  Then for $v\in V$ with $v=a_1(1,0)+a_2(0,1)$, we have
\begin{equation*}
\begin{split}
v.\gamma &= a_1(1,0).\gamma+a_2(0,1).\gamma\\
&= a_1(0,1)+a_2(-1,0)\\
&= (-a_2,a_1).
\end{split}
\end{equation*}
\end{example}

\begin{proposition}
Suppose $B=(v_1,\ldots,v_n)$ is a basis of an $F$-space $V$ and we have a map $B\times G\rightarrow V$, $(v_i, g)\mapsto v_i.g$ such that
\begin{description}
\item[(A1)] $v_i.(gh)=(v_i.g).h;$
\item[(A2)] $v_i.1=v_i.$
\end{description}
Then $V$ is an $FG$-module with $V\times G\rightarrow V$ defined by $(\sum a_i v_i).g=\sum a_i(v_i.g)$.
\end{proposition}

\noindent In particular, if $B$ is a $G$-set then $V$ is an $FG$-module.

\begin{definition}
Let $V$ be an $F$-space with basis $B=(v_1,\ldots,v_n)$.  If $B$ is a $G$-set then $V$ is an $FG$-module called a \emph{permutation module}.  In this case, the matrix $[g]_B$ is a permutation matrix, it has exactly one non-zero entry 1 in every row and column.
\end{definition}

\begin{example}
$G=Sym_4$ acts on $B=\{v_1,\ldots,v_n\}$ via $v_i.g=v_{i.g}$.  If $g=(1,2)$ then
$$[g]_B=\left(\begin{array}{cccc}
0 & 1 & 0 & 0 \\
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{array}\right).$$
Note that $[g^{-1}]_B=[g]_B^T$.  For example, if $g=(1,2,3,4)$ then
$$[g]_B=\left(\begin{array}{cccc}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
\end{array}\right)\textrm{ and }
[g]_B^T=\left(\begin{array}{cccc}
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
\end{array}\right).$$
The matrix $[g]_B^T$ corresponds to $(1,4,3,2)=(1,2,3,4)^{-1}=g^{-1}$.
\end{example}

\begin{definition}
Let $X=\{x\}$ and $x.g=x$.  The vector space $V$ with basis $X$ is the \emph{trivial $FG$-module}.  We have $V=\{\lambda x:\lambda\in F\}\cong F^1=F$.
\end{definition}

\begin{definition}
Let $X=G$ be acted upon by right multiplication.  The vector space $V$ with basis $X$ is the \emph{regular $FG$-module}.  Denote $V=FG=\{\sum_{g\in G}\alpha_g g:\alpha_g\in F\}$.  We have a linear action $FG\times G\rightarrow FG$.
\end{definition}

\begin{definition}  The \emph{group algebra} is $FG$ with multiplication defined by
$$\left(\sum_{g\in G}\alpha_g g\right)\left(\sum_{h\in G}\beta_h h\right)=\sum_{g\in G}\gamma_g g$$.
\end{definition}

We need to show what $\gamma_g$ is:
\begin{itemize}
\item $(\sum_{g\in G}\alpha_g g)h=\sum_{g\in G}\alpha_g\underbrace{(gh)}_k=\sum_{k\in G}\alpha_{kh^{-1}}k=\sum_{g\in g}\alpha_{gh^{-1}} g$.
\item $(\sum_{g\in G}\alpha_g g)(\sum_{h\in G}\beta_h h) = \sum_{h\in G}\beta_h (\sum_{g\in G}\alpha_g g)h \\
= \sum_{h\in G}\beta_h (\sum_{g\in G} \alpha_{gh^{-1}} g) = \sum_{g\in G} \underbrace{(\sum_{h\in G} \alpha_{gh^{-1}}\beta_h)}_{\gamma_g} g.$
\end{itemize}

\textbf{Recall:} A \emph{ring} is a set R equipped with two binary operations $+:R\times R\rightarrow R$ and $\cdot:R\times R\rightarrow R$ such that:
\begin{itemize}
\item $(R, +)$ is an abelian group.
\item $(R, \cdot)$ is a monoid.
\item Distributivity holds, i.e. $a(b+c)=ab+ac$ and $(a+b)c=ac+bc$ for all $a, b, c\in R$.
\end{itemize}

\begin{proposition}
$FG$ is a ring with identity $1\in G$ and $(\lambda r)s=\lambda(rs)=r(\lambda s)$ for all $\lambda\in F$ and all $r, s\in FG$.
\end{proposition}

\begin{corollary}
$FG$ is an $F$-algebra, i.e., and $F$-space and a ring at the same time, with $(\lambda r)s=\lambda(rs)=r(\lambda s)$ for all $\lambda\in F$ and all $r, s\in FG$.
\end{corollary}

Examples of $F$-algebras are polynomials, $n\times n$ matrices, and $End_F(V)$.

\begin{definition}
Let $A$ be an $F$-algebra and $V$ be an $F$-space with $V\times A\rightarrow V,\ (v,a)\mapsto v.a$.  Then $V$ is an $A$-module if:
\begin{description}
\item[(A1)] $v.ab=v.a.b$
\item[(A2)] $v.1=v$
\item[(L2)] $(u+v).a=u.a+v.a$
\item[(L3)] $v.(a+b)=v.a+v.b$
\end{description}
\end{definition}

What about $(L1):\ (\lambda v).g=\lambda(v.g)$?\\
We have $1\in A$ so $F\cong F.1\subseteq A$.  For $\lambda\in F:\ \lambda v=v\lambda=v.(\lambda 1)$.  Then $(A1)$ applies, implying $(L1)$.

$V$ is an $FG$-module if and only if $V$ is an $A$-module, i.e. the two sets of action axioms are compatible. Now we can consider $A$-modules for $A = FG$, or $A = End_{F} (\omega)$.

\begin{center}
\textbf{Submodules}
\end{center}
Let $A$ be an $F$-algebra.
\begin{definition}
Let $V$ be an $A$-module. A subset $\omega \subseteq V$ is a submodule of $V$ if:
\begin{itemize}
\item $\omega \leq_{F} V$ (subspace).
\item $w \cdot a \in \omega$ for all $w \in \omega$, $a \in A$.
\end{itemize}
notation: $\omega \leq_{A} V$.
\end{definition}

\begin{example}
Let $G = D_{8}$. $$V = \left\langle v_{1}, v_{2}, v_{3}, v_{4} \right\rangle_{F},$$ $$\omega = v_{1} + v_{2} + v_{3} + v_{4}$$
$$\omega \cdot g = \omega$$
$$\left\langle \omega \right\rangle_{F} \leq_{F} V$$
\end{example}

\begin{definition}
$A$-homomorphism: let $V, W$ be $A$-modules. A map $\varphi: V \rightarrow W$ is an $A$-homomorphism from $V$ to $W$ if:
\begin{itemize}
\item $\varphi$ is linear.
\item $\varphi (v \cdot a) = \varphi ( v ) \cdot a$ for all $v \in V$, $a \in A$.
\end{itemize}
\end{definition}

\begin{proposition}
If $\varphi : V \rightarrow W$ is an $A$-homomorphism then:
\begin{itemize}
\item $Ker ( \varphi ) = \left\{ v \in V : \varphi ( v) = 0 \right\}$
\item $Im ( \varphi ) = \left\{ \varphi (v)  : v \in V \right\} \leq_{A} W$
\end{itemize}
\end{proposition}

\begin{example}
$\varphi: V \rightarrow W : v \mapsto 0$ is an $A$-homomorphism.
\end{example}

\begin{example}
$\varphi: V \rightarrow V: v \mapsto \lambda \cdot v$ for some $\lambda \in F$ is an $A$-homomorphism. $Ker ( \varphi ) = 0 \Leftrightarrow \lambda \neq 0$.
\end{example}

\begin{example}
$G \rightarrow X $ vector space with basis $X$. $W = F$ trivial. $\varphi ( \sum{\lambda_{i}}{x_{i}}) = \sum \lambda_{i}$ defines an $A$-homomorphism with: $Ker ( \varphi ) = \left\{ \sum \lambda_{i} x_{i} : \sum \lambda_{i} = 0 \right\} \leq_{FG} V.$
\end{example}

An invertible $A$-homomorphism $\varphi: V \rightarrow W$ is called an $A$-isomorphism. Write $V \cong_{A} W$ if there exists an $A$-isomorphism $\varphi: V \rightarrow W$.

\begin{proposition}
$\cong_{A}$ is an equivalence relation.
\end{proposition}

\begin{theorem}
Let $V$ be an $A$-module with basis $B'$. Then $V \cong_{A} W \Leftrightarrow$ the matrix representations $a \mapsto [a]_{B}$ and $a \mapsto [a]_{B'}$ are equivalent.
\end{theorem}

\begin{center}
\textbf{New Module from Old}
\end{center}

Let $V$ and $W$ be $A$-modules with bases $B = (v_{1}, \ldots, v_{n})$ and $B = ( w_{1}, \ldots, w_{n} )$. The (external) direct sum is defined to be $V \oplus W = \left\{ (v, w) : v \in V, w \in W \right\}$. With $(v, w) + (v', w') = (v + v', w + w')$ and $(v, w) \cdot a = (v \cdot a, w \cdot a )$. This is an $A$ module with basis $B \sqcup B'$.

Tensor product: $V \otimes W = \left\{ \sum v \otimes w \right\}$ with $(v \otimes w ) \cdot a = (v a \otimes w a)$ is an $A$-module with basis $B \times B'$.

The (internal) direct sum decomposition: Let $V$ be an $A$-module with submodules $v_{1}, \ldots, v_{n}$, $v_{i} \neq 0$. Then $V = \oplus v_{i} = v_{1} \oplus \ldots \oplus v_{n}$. If every $v \in V$ can be written uniquely in the form $v = v_{1} + \ldots + v_{n}$ with $v_{i} \in V_{i}$.

\begin{example}
Let $G = 1$, $V$ an $F$-space with basis $B = (v_{1}, \ldots, v_{n})$. Then as $FG$-module $V = F_{v_{1}} \oplus \ldots \oplus F_{v_{n}}$.
\end{example}
An $A$-module $V$ is:
\begin{itemize}
\item simple if 0 and $V$ are its only submodules.
\item reducible otherwise.
\item decomposable if $V = U \oplus W$ with $U \neq 0$ and $W \neq 0$.
\item indecomposable otherwise.
\end{itemize}
Question: Is an $A$-module reducible if and only if it is decomposable?

\begin{definition}
An $A$-module $V$ is simple if $0, V \leq_{A} V$ are the only submodules of $V$ (reducible otherwise).
Decomposable if $V = U \oplus W$ for submodules $0 \neq U, W \leq_{A} V$ (and indecomposable otherwise).
\end{definition}
Same notation for the representation $\delta: A \rightarrow End(V)$. In terms of matrices $\delta$ reducible means:
 \begin{equation*}
\mbox{$\delta (a )$} = \left[
\begin{array}{ccc}
     \delta_{1} (A) & \vline & 0 \\
     \hline
     \ast & \vline & \delta_{2} (A) \\
\end{array}
\right]
\end{equation*}
For non-zero representation $\delta_{1}, \delta_{2}$ of $A$, $0 \neq U \subset_{A} V$ take a basis $u_{1}, \ldots, u_{l}$ of $U$. Extend this to a basis $(u_{1}, \ldots, u_{l}, w_{l+1}, \ldots, w_{n})$ of $V$. If $\delta$ is decomposable:
 \begin{equation*}
\mbox{$\delta (a )$} = \left[
\begin{array}{ccc}
     \delta_{1} (A) & \vline & 0 \\
     \hline
     0 & \vline & \delta_{2} (A) \\
\end{array}
\right]
\end{equation*}
$V = U \oplus W$, where $u_{1}, \ldots, u_{l}$ is a basis for $U$ and $w_{l + 1}, \ldots, w_{n}$ is a basis for $W$ and together they form a basis for $V$.

Question: Is an $A$-module reducible if and only if it is decomposable?
Answer: It depends: this divides representation theory into ordinary representation theory, to which the answer is yes, and modular representation theory, where the answer is no.

\begin{center}
\textbf{Simple Modules}
\end{center}
$A$ an $F$-algebra, $V$ finite dimensional $A$-module.

\begin{theorem}
(Jordon-H\"{o}lder): Any two composition series $0 = v_{0} <_{A} v_{1} <_{A} \ldots <_{A} v_{n}$ such that $v_{k} / v_{k - 1}$ is simple, have the same length $n$ and the same composition factor up to ordering and isomorphism.
\end{theorem}
As a consequence we can choose a basis of $V$ so that:
\begin{equation*}
\mbox{$\delta (a )$} = \left[
\begin{array}{cccc}
     \delta_{1} (A) & 0 & \cdots & 0\\
     \ast & \delta_{2} (A)& \  & \vdots\\
     \vdots & \  & \ddots & 0 \\
     \ast & \cdots & \ast & \delta_{n} (A)\\
\end{array}
\right]
\end{equation*}
where the $\delta_{i}$  are representations on simple factors.

If $A$ (as an $A$-module) has a composition series (which it has if $dimA < \infty$) then $A$ (the algebra) has only finitely many simple modules up to isomorphism, as a consequence of the following lemma:
\begin{lemma} \label{schur}
\label{simple}
Let $V$ be an $A$-module then:
\begin{enumerate}
\item $V$ simple $\Rightarrow V \cong_{A} A / M$ for some maximal right ideal of $A$ (submodules of the regular $A$-module $A$ are right ideals of the ring $A$).
\item $V$ simple $\Leftrightarrow v \cdot A = V$ for all $0 \neq v \in V$
\item $V$ simple $\Rightarrow End_{A} (V)$ is a division ring (Schur's lemma).
\end{enumerate}
\end{lemma}

 \begin{proof}
(2) Choose $v \in V$ and consider: $$\varphi: A \rightarrow V$$ $$a \mapsto v \cdot a$$
and consider $\varphi$ as an $A$-module homomorphism. $V$ simple $\Rightarrow v \cdot A = Im \varphi = \begin{cases}
0\\
V
\end{cases}$
$v \neq 0$, $v \cdot 1 = V \in Im \varphi \neq 0$. Hence $v \cdot A = V$ for $v \neq 0$
Conversely; Suppose $U \neq 0$ is a submodule of $V$ pick $0 \neq v \in U$, then $V = v \cdot A \leq U \leq V$.

(1) Homomorphism theorem: $$A / Ker \varphi \cong_{A} Im \varphi.$$

(3) Show: non-zero $A$-module homomorphism $\varphi: V \rightarrow V$ are invertible. $V$ simple $$Ker \varphi = \begin{cases}
0 & \varphi \mbox{ is invertible}\\
V & \mbox{then }\varphi = 0
\end{cases}$$
\end{proof}

If $F$ is algebraically closed: the characteristic polynomial $\chi_{\varphi}$ has a root $\alpha \in F$. $\varphi-\alpha id_{V}$ is not invertible hence 0; $\varphi = \alpha id_{V}. End_{A} (V) \cong F$.

\begin{center}
\textbf{Spinning Algorithm}
\end{center}

Let $A$ be an $F$-algebra and $V$ be an $A$-module.  We consider Lemma \ref{simple}(2) which says that $V$ is simple if and only if $v.A=V$ for all $0\neq v\in V$. We want to use an algorithm to find $v.A$.  Assume $A$ is generated by elements $M:=\{a_1,\ldots,a_m\}$ as an $F$-algebra.  The input of this algorithm is $0\neq v\in V$.  The output is an $F$-basis of $v.A$.  The algorithm is as follows:
\begin{enumerate}
\item $B\leftarrow (v)$
\item for $b\in B$:
\item \ \ for $m\in M$:
\item \ \ \ \ $w\leftarrow b.m$
\item \ \ \ \ if $w\not\in\langle B\rangle_F$: append $w$ to the list $B$.
\item return $B$
\end{enumerate}

To see that this is what we need, note that
\begin{itemize}
\item The algorithm terminates because $V$ is finite dimensional.
\item $B$ is linearly independent by construction.
\item $B$ spans $v.A$ since $v\in B\subseteq v.A\subseteq\langle B\rangle_F .A\subseteq\langle B\rangle_F\subseteq v.A$ so $\langle B\rangle_F=v.A$
\end{itemize}

To test simplicity, we could compute $v.A$ for all $0\neq v\in V$, but but there could be too many $0\neq v\in V$.  We only need to test one $v$ from each 1-dimensional subspace, however this could still be too many.

\begin{center}
\textbf{Duality}
\end{center}

$V^*=Hom(V,F)=\{\lambda:V\rightarrow F$ linear$\}$.  For $a\in A$ the rule $a\lambda:v\mapsto\lambda(v.a)$ turns $V^*$ into a \textbf{left} $A$-module.\\

We could try to define a \textbf{right} $A$-module by $\lambda.a(v)=\lambda(v.a)$.  However,
$$(\lambda.a).a'(v)=(\lambda.a)(v.a')=\lambda((v.a').a)=\lambda(v.(a'a))$$
and
$$\lambda.(aa')(v)=\lambda(v.(aa')).$$
These are not equal so we do not have a right module.\\

If $A=FG$ then it has a basis of invertible elements $g\in G$.  We can define $\lambda.g:v\mapsto\lambda(v.g^{-1})$ and extend this linearly to all of $A$.  This turns $V^*$ into a \textbf{right} $A$-module called the \emph{contragredient module} of $V$.

\begin{theorem}[Duality Theorem]
The map $W\mapsto W^0:=\{\lambda\in V^*:\lambda(w)=0$ for all $w\in W\}=\{\lambda\in V^*:W\leq ker\lambda\}$ is an inclusion reversing anti-isomorphism of the poset of $A$ submodules of $V$ onto that of $V^*$.
\end{theorem}

For example
$$\xymatrix{V \ar@{-}[d] & V^*=(0)^0 \ar@{-}[d] \\
W \ar@{-}[d] & U^0 \ar@{-}[d] \\
U \ar@{-}[d] & W^0 \ar@{-}[d] \\
0 & 0=(V^*)^0}$$
For $U\leq_A W\leq_A V$ we have $(W/U)^*\cong_A U^0/W^0$.  In particular, $V$ is simple $\Leftrightarrow V^*$ is simple.

\begin{theorem}[Norton's Irreducibility Criterion]
Let $F$ be a field, $A$ an $F$-algebra, and $V$ an $A$-module.  For $a\in A$, let $ker_V(a)=\{v\in V:v.a=0\}$.  Suppose $ker_V(a)\neq 0$ for some $0\neq a\in A$. Then $V$ is simple if and only if the following conditions hold:
\begin{enumerate}[a)]
\item $v.A=V$ for all $v\in ker_V(a)\backslash\{0\}$;
\item $A.\lambda=V^*$ for some $\lambda\in ker_{V^*}(a)$.
\end{enumerate}
\end{theorem}

Our hope is that $dim_F ker_V(a)=1$.  Then we will only need to test one $v$ and one $\lambda$ to see if $V$ is simple.

\begin{example}
Let $G=\Sym_3=\langle a, b\rangle$ where $a=(1,2)$ and $b=(2,3)$.  Then
$$\delta(a)=\left(\begin{array}{cc}
-1  & 0 \\
1 & 1 \\
\end{array}\right)
\textrm{ and }
\delta(b)=\left(\begin{array}{cc}
1  & 1 \\
0 & -1 \\
\end{array}\right).$$
We have $V=F^{1\times 2}$ and $V^*=F^{2\times 1}$.  Consider
$$\delta(1+a)=\left(\begin{array}{cc}
0  & 0 \\
1 & 2 \\
\end{array}\right).$$
We want to use Norton's irreducibility criterion.  We have $ker_V(1+a)=\langle(1,0)\rangle_F$ and $(1,0).A=V$ so $a)$ is satisfied.  Also,
$$ker_{V^*}(1+a)=\langle\left(\begin{array}{c} -2 \\ 1 \\ \end{array}\right)\rangle_F\textrm{ and }A.\left(\begin{array}{c} -2 \\ 1 \\ \end{array}\right)=\langle\left(\begin{array}{c} -2 \\ 1 \\ \end{array}\right), \left(\begin{array}{c} 1 \\ 1 \\ \end{array}\right)\rangle_F=V^*$$
if $-2\neq 1$. Hence $b)$ is satisfied if $-2\neq 1$.  Therefore $V$ is simple unless $char\ F=3$.
\end{example}

Norton's irreducibility criterion relies on the following lemma:

\begin{lemma} \label{pre}
Let $V$ be a finite dimensional vector space $\left( dim_{F} V < \infty \right)$ and let $\varphi \in End_{F} (V)$. If $W \leq V$ is $\varphi$ invarient ($\varphi (w) \in W$ for all $w \in W$), then: $W \cap ker \varphi = 0 \Rightarrow ker \varphi^{T} \leq W^{0}$. Where $W^{0} = \left\{ x \in V^{\ast} : x|_{W} = 0 \right\} $ .
\end{lemma}

\begin{proof}
$ker \varphi^{T} = \left\{ x \in V^{\ast} : 0 = \varphi^{T} (x) = x \circ \varphi \right\} = (Im \varphi)^{0}$. Now $W \cap ker( \varphi ) = 0 \Rightarrow \varphi |_{W} $ is injective and hence surjective. $\Rightarrow W \leq Im \varphi \stackrel{duality}{\Longrightarrow} W^{0} \geq (Im \varphi)^{0} = ker \varphi^{T}$.
\end{proof}

\begin{proof} (Norton's Irreducibility Criterion):
$\left( \Rightarrow \right)$ This comes from part (2) of Lemma \ref{schur} and the fact that $V$ is simple $\Leftrightarrow V^{\ast}$ is simple.

$\left( \Leftarrow \right)$ Assume $W <_{A} V$ and show $W = 0$.
$ker_{V} (c) \cap W = 0$. $$\stackrel{lemma \ref{pre}}{\Longrightarrow} ker_{V^{\ast}} (c) \leq W^{0} \leq_{A} V^{\ast}.$$
$$\Rightarrow W^{0} = W^{\ast} \Rightarrow W = 0.$$
\end{proof}

\begin{center}
\textbf{The Meat Axe Algorithm (Richard Parker 1980)}
\end{center}
Let $A$ be an $F$-algebra generated by elements $a_{1}, \ldots, a_{k}$. Let $F$ be a (finite) field and $\delta: A \rightarrow F^{n \times n}$ acting on $V = F^{1 \times n}$.

Input: matrices $\delta (a_{i})$, $i = 1, \ldots, k$.

Output: either "$\delta$ irreducible" or matrices for $A$ acting on $0 <_{A} W <_{A} V$ and on $V/W$.

(1) Repeat:

Pick $c \in A$ (uniformly and randomly) until $ker_{V} (\delta (c)) \neq 0$

(3) for all $o \neq V \in ker_{V} (\delta(c))$ (up to scalar multibles:

(a) Compute a  basis $B = (b_{1}, \ldots, b_{n} )$ of $v \cdot \left\langle \delta (a_{i}) \right\rangle$ (Spinning algoritm)

(b) If $m < n$ (submodule found, $W = \left\langle B \right\rangle_{F}$) extend $B$ to a basis $C$ of $F^{n}$ and compute the matries for $a_{i}$  relative to $C$. Return $\left( \left\{ \delta^{'} (a_{i}) \right\}, \left\{ \delta^{''}(a_{i}) \right\} \right)$.

(4) (If we get here: $v\cdot A =V$ for all $v \in ker_{V} (C)$). Find one $v \in F^{n}$ such that $v \cdot \delta (a)^{T} = 0$.

(a) Compute basis $B = ( b_{1}, \ldots, b_{n})$ of $v \cdot \left\langle \delta (a_{i})^{T} \right\rangle$ (Spinning algorithm).

(b)  If $m < n$ extend $B$ to a basis $C$ of $F^{n}$. Compute matrices for $a_{i}$ relative to $C$.

Return $\left( \left\{ \delta^{'} (a_{i}) \right\}, \left\{ \delta^{''} (a_{i} ) \right\} \right)$.

\begin{center}
\textbf{Higman-Sims Group}
\end{center}

We now want to use the Meat Axe Algorithm to analyse the Higman-Sims group, HS, which is a group of permutations of a 100 element set.  We do this using GAP.  We construct the permutation module of HS over $\mathbb{F}_2$ and then ask for bases of all submodules.\\
\verb"gap> G:=PrimitiveGroup(100, 3);"\\
\verb"gap> module:=PermutationGModule(G, GF(2));"\\
\verb"gap> bsm:=MTX.BasesSubmodules(module);"\\
The list \verb"bsm" of bases for all submodules of \verb"module", written as matrices.  We now want a list of the submodules as vector spaces.\\
\verb"gap> sm:= List(bsm, b -> Submodule(GF(2)^100, b));"\\

Consider the incidence matrix of the poset of submodules, i.e., $M=(m_{ij})$ where
$$m_{ij}=\left\{\begin{array}{ll}
1, & \hbox{$V_i\geq V_j$;} \\
0, & \hbox{otherwise.}
\end{array}\right.$$
The condition $V_i\geq V_j$ is checked in GAP by \verb"IsSubspace" which will give an answer of either \verb"true" or \verb"false".  For the incidence matrix, we need 1 and 0 instead of true and false.\\
One notation for this would be [condition]=$\left\{\begin{array}{ll} 1, & \hbox{if condition true;} \\ 0, & \hbox{if false.}\end{array}\right.$ For example, we could write $\sum_{i=m}^n a_i=\sum_{i\in\mathbb{Z}}[m\leq i\leq n]a_i$.  In our case, we would have
$$m_{ij}=[V_i\geq V_j].$$
In GAP we write\\
\verb"gap> Iverson:= function(bool) if bool then return 1; else"\\
\verb"> return 0; fi; end;"\\
To construct the incidence matrix:
\verb"gap> mat:=[ ];"\\
\verb"gap> l:= Length(sm);"\\
\verb"gap> for i in [1..l] do"\\
\verb">      mat[i]:=[ ];"\\
\verb">      for j in [1..l] do"\\
\verb">        mat[i][j]:= Iverson(IsSubspace(sm[i], sm[j]));"\\
\verb">      od;"\\
\verb">    od;"\\
\verb"gap> mat;"\\
This will give a lower triangular matrix, where the diagonal entries will have entry 1 for the trivial inclusion.  We can get rid of these paths in the matrix, so that we have the incidence matrix of the paths of length greater than 0.\\
\verb"gap> new:= mat - mat^0;"\\
We now find the incidence matrix which shows only the paths of length 1.\\
\verb"gap> new:= new - new^2;"\\
\verb"gap> new:= List(new, x -> List(x, y -> Iverson(y>0)));"\\
We then use this matrix and the dimension of the submodules, given by:\\
\verb"gap> List(sm, Dimension);"\\
to draw a graph of the inclusions of the submodules, using the dimension of the submodules as the vertices.
$$\xymatrix{ && 100 \ar@{-}[d] \\
&& 99 \ar@{-}[d] \\
&& 79 \ar@{-}[dll] \ar@{-}[dl] \ar@{-}[dr] \ar@{-}[drr] \\
23 \ar@{-}[d] \ar@{-}[dr] \ar@{-}[drrr] & 78_1 \ar@{-}[dl] \ar@{-}[drr] && 78_2 \ar@{-}[dll] \ar@{-}[dr] & 78_3 \ar@{-}[dl] \ar@{-}[d]\\
22_1 \ar@{-}[drr] & 22_2 \ar@{-}[dr] && 22_3 \ar@{-}[dl] & 77 \ar@{-}[dll] \\
&& 21 \ar@{-}[d] \\
&& 1 \ar@{-}[d] \\
&& 0}$$
From the graph we can see that $M$ is  not simple but $M$ is indecomposable.\\
We can compute the composition factors and the multiplicity of each factor in a composition series (in the graph, a path from top to bottom is a composition series).\\
\verb"gap> cf:= MTX.CollectedFactors(module);;"\\
\verb"gap> List(cf, x -> x[1].dimension);"\\
\verb"[1, 20, 56]"\\
\verb"gap> List(cf, x -> x[2]);"\\
\verb"[4, 2, 1]"\\
\verb"gap> List(cf, x -> MTX.IsAbsolutelyIrreducible(x[1]));"\\
\verb"[true, true, true]"\\
Hence the permutation module has only 3 composition factors up to isomorphism, with multiplicities 4, 2, and 1.

\begin{center}
\textbf{Semisimplicity}
\end{center}

\begin{definition}
A module $V$ is called \emph{semisimple} if it is a sum $V=\sum_i S_i$ of simple modules $S_i$.
\end{definition}

Let $U$, $W$ be in $F$-space: $U + W = \left\{ u + w: u \in U, w \in W \right\}$. $V = U \oplus W = \left\{ (u,w) : u \in U, w \in W \right\}$. If each $v = u + w$ in a unique way $V= U + W$ for some $u \in U$, $w \in W$. $U + W = U \oplus W \Leftrightarrow U \cap W = \left\{ 0 \right\}$.

\begin{lemma}
The following are equivalent:
\begin{enumerate}
\item $V$ is semisimple.
\item $V$ is a direct sum of simple modules.
\item Every submodule $W$ of $V$ has a complement $W' \leq_{A} V$: $V = W \oplus W'$ (every submodule is a direct summand).
\end{enumerate}
\end{lemma}

\begin{definition}
The algebra $A$ is called \emph{semisimple} if it semisimple as an $A$-module (under right multiplication).
\end{definition}

\begin{corollary}
\begin{itemize}
\item Sums submodules and factor modules of semisimple modules.
\item $A$ semisimple $\Leftrightarrow$ every $A$-module is semisimple.
\end{itemize}
\end{corollary}

$V$ is a finite dimensional $A$-module, then $V$ is a quotient of $A \oplus \ldots \oplus A$.
$$V = \left\langle v_{1}, \ldots, v_{l} \right\rangle$$
$$v = \sum_{i= 1}^{l} {a_{i}}{v_{i}} \; , a_{i} \in A$$
$$A \oplus \ldots \oplus A \rightarrow V \text{ surjective}$$
$$\left( a_{1}, \ldots, a_{l} \right) \mapsto \sum{a_{i}}{v_{i}}$$
What about group algebras?

\begin{theorem}[Maschke's Theorem]
Let G be a finite group. $A = FG$. Then $A$ is semisimple if and only if $\left| G\right|$ is not zero in $F$, i.e. the characteristic of $F$ does not divide the order of $G$.
\end{theorem}

\begin{proof}
Assume the characteristis of $F$ does not divide the order of $G$. Let $U \leq_{A} A$. Show that $U$ has a complement. $W \leq_{A} A$. $U \oplus U'$ as $F$-space (not unique) (extend a basis of $U$ to all of $A$) $B = \left(b_{1}, \ldots, b_{s} \right)$ and $B' = \left( b_{s}, \ldots, b_{\left| G \right|} \right)$. $\pi \in End_{F} A$: projection of $A$ into $U$ with kernel $U'$.
$\pi \left( b_{i} \right) = 
\begin{cases}
b_{i} & \mbox{if } i \leq S\\
0 & \mbox{if } i > S
\end{cases}$.
Define $\widetilde{\pi} \in End_{F} A$ by $\widetilde{\pi}_{a \in A} (a) = \frac{1}{\left| G \right|} \sum_{g \in G} \pi^{g}$. Where $\pi^{g}$ is defined by $\pi^{g} = \pi \left( a \cdot g^{-1} \right)g$. We want to show:
\begin{itemize}
\item $\widetilde{\pi}^{2} = \widetilde{\pi}$
\item $Im(\widetilde{\pi}) = Im( \pi)$ 
\item $\widetilde{\pi} \in End_{A} A$
\end{itemize}
$\pi^{g}$ defines an action of $G$ on $End_{F} A$. Check:
$$\pi^{gh} (a) = \pi \left( a \left( gh \right)^{-1} \right) gh$$
$$\left( \pi^{g} \right)^{h} (a) = \pi^{g} \left(a \cdot h^{-1} \right) h$$
$$ = \left( \pi \left( a \cdot h^{-1} \right) g^{-1} \right) gh$$
$$ \pi^{gh} (a)$$
Now suppose $\pi^{2} = \pi$ with $Im \pi = U$ then:
\begin{itemize}
\item $\left( \pi^{g} \right)^{2} = \pi^{g}$
\item  $Im( \pi^{g} ) = Im (\pi)$
\end{itemize} 
The first item is clear from the fact that $\pi$ and $\pi^{g}$ are both projection mappings.
The second item follows from $ \left( \pi^{'} \right)^{2} = \pi^{'}$ with $Im \pi^{'} = Im \pi$
$\pi \circ \pi^{'} = \pi^{'}$, $\pi^{'} \circ \pi = \pi$.
$$(\pi + \pi^{'} )^{2} = (\pi + \pi^{'} ) (\pi^{'} + \pi)$$
$$ = 2 \pi + 2 \pi^{'}$$
$$\Rightarrow \left( \frac{1}{2} \left( \pi + \pi^{'} \right) \right)^{2}$$
$$ = \frac{1}{2} \left( \pi + \pi^{'} \right)$$

Conversely assume the characteristic of $F$ divides the order of $G$ then:
$Inv_{G} (A) = \left\langle \sum_{g \in G} g \right\rangle_{F} = \sum_{g \in G} 1 = \left| G \right| = 0$. This lies in $Inv^{G} (A) = \left\{ \sum_{g \in G} a_{g} g : \sum_{g \in G} a_{g} = 0 \right\}$. $G$ acts trivially on $A/ Inv^{G} (A)$. $Inv_{G} (A)$ is the largest submodule on which $G$ acts trivially. This implies $Inv^{G}_{v} (A)$ cannot have a complement.

If the characteristic of $F = p$ and divides the order of $G$ then this is modular representation theory. However if the characteristic of $F = 0$ then this is ordinary representation theory.
\end{proof}
\nocite{*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{amsplain}
\bibliography{comrepth}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
